gcpProjectName: 'elife-data-pipeline' #mandatory
importedTimestampFieldName: 'data_hub_imported_timestamp' #mandatory
stateFile:
  bucketName: 'ci-elife-data-pipeline'
  objectName: 'airflow-config/keyword-extraction/{ENV}-state/key_extraction_pipeline_state_test.json'
keywordExtractionPipelines:
  - pipelineID: keywords_from_public_editor_profile_keywords  #mandatory
    defaultStartTimestamp: '2000-01-01 00:00:00+0000' #format must be "%Y-%m-%d %H:%M:%S%z"
    stateTimestampField: imported_timestamp
    sourceDataset: '{ENV}'  #mandatory
    destinationDataset: '{ENV}'  #mandatory
    destinationTable: "public_editor_profile_keywords_extracted_keywords"  #mandatory
    queryTemplate: |
      SELECT
        name,
        CONCAT('the ', ARRAY_TO_STRING(keywords, ', ')) AS keywords_csv,
        imported_timestamp
      FROM `elife-data-pipeline.de_dev.mv_public_editor_profile`
    #to reduce properties to configure,
    #it is assumed that query template placeholders for  project, dataset, and latest state value are
    #{project}, {dataset} and {latest_state_value}
    textField: 'keywords_csv'  #mandatory
    idField: 'name'
    tableWriteAppend: 'true'
    limitRowCountValue:  #config element primarily used during test
    spacyLanguageModel: 'en_core_web_lg'
    provenance:
      type: fixedValue #either sourceDataFieldName or fixedValue (DEFAULT)
      # provide EITHER the field in source data from which to
      # retrieve the value OR the fixed value to enter into provenance
      # field which indicate the kind of data source from which the keywords
      # is extracted
      value: public_editor_profile
